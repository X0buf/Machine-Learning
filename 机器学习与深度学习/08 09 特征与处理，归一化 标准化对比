
[TOC]

# 数据的特征预处理

1. 特征处理的方法
2. sklearn特征与处理API

## 特征处理是什么

- 通过特定的统计方法（**数学方法**）将数据转换成**算法要求的数据**

- 数值型数据：标准缩放：
  1. 归一化
  2. 标准化
  3. 缺失值
- 类别型数据：one-hot 编码
- 时间类型：时间的切分

## sklearn特征处理API

- sklearn.preprocessing

## 归一化

- **特点：通过对原始数据进行变化把数据映射到（默认为[0,1]）之间**
- 公式： $X'=\frac{x-mean}{(\sigma)}$        $X''=x'*(mx-mi)+mi$
- 注：作用于每一列，max为一列的最大值，min为一列的最小值，那么X''为最终结果，m x ，mi分别为指定区间值默认m x为1，mi为0

### MinMaxScaler语法

#### sklearn归一化

1. API：sklearn.preprocessing.**MinMaxScaler**

#### MinMaxScaler语法

- MinMaxScalar（feature_range=(0,1)...）
  - 每个特征缩放到给定范围（默认[0,1]）
  - MinMaxScalar.fit_tranform(X)
    - X:numpy array格式的数据[n_samples,n_features]
    - 返回值:转换后的形状相同的array

### 归一化步骤

1. 实例化MinMaxScalar
2. 通过fit_transform转换

### 问题：如果数据中异常点较多，会有什么影响？

### 归一化总结

- 注意在特定场景下最大值，最小值是变化的，另外，最大值与最小值非常容易受**异常点**影响，所以这种方法**鲁棒性**较差，只适合传**统精确小数据场景**。

# 归一化以及标准化对比

## 标准化

1. **特点 通过对原始数据进行变换把数据变换到均值为0，标准差为1范围内**
1. **标准化不易受到异常点影响**
2. 公式 ：$X'=\frac{x-mean}{(\sigma)}$
   - 注：作用于每一列，mean为平均值，$\sigma$为标准差
   - var成为方差，$var=\frac{(x1-mean)^2+(x2-mean)^2+...}{n(每个特征的样本数)}，\sigma=\sqrt var$  :smile: 第一个公式
   - 其中，方差（**考量数据的稳定性**）

### 结合归一化来谈标准化

- 对于归一化来说：如果出现异常点，影响了最大值和最小值那么结果显然会发生改变
- 对于标准话来说：如果出现异常点，由于**具有一定数据量，少量的异常点对于平均值的影响并不大**，从而方差改变较小

### sklearn特征化API

- sklearn特征化API：scikt-learn.preprocessing.**StandardScaler**
- StandardScaler语法
  - StandardScaler(...)
    - 处理之后每列来说所有数据都聚集在均值0附近方差为1
    - StandardScaler.fit_ttansforn(X)
      - X:numpy array格式的数据[n_samples,n_features]
      - 返回值：转换后的形状相同的array
    - StandardScaler.mean_
      - 原始数据中每列特征的平均值
    - StandardScaler.std_
      - 原始数据每列特征的方差
