# 数据降维

## 特征选择

- 特征选择的原因
  - 冗余：部分特征的相关度高，容易消耗计算性能
  - 噪声：部分特征对预测结果有影响

1. 特征选择是什么

   - 特征选择就是单纯地从提取到的**所有特征中选择部分特征**作为训练集特征，特征比**选择前和选择后可以改变值，也不改变值**，但是选择后的特征维数肯定比选择前小，毕竟只选择了其中一部分特征。
   - 主要方法（三大武器）：
     - **Filter （过滤式） ：VarianceThreshold**
     - **Embedded（嵌入式）：正则化，决策树**
     - Wrapper（包裹式）

2. sklearn特征选择API

   1. sklearn.feature_selection.VarianceThreshold

   2. VarianceThreshold语法

      - VarianceThreshold(threshold=0.0)
      - 删除所有低方差特征
      - Variance.**fit_transform**(X)
        - X:numpyarray格式的数据[n_samples,n_features]
        - **返回值：训练集差异低于threshold的特征将被删除。**
        - **默认值是保留所有非零方差特征，即删除所有样本中具有相同值的特征**

   3. VarianceThreshold 流程（代码演示）

      1. 初始化VarianceThreshold，指定阈值方差

      2. 调用fit_transform

         [[0,2,0,3],

         [0,1,4,3],

         [0,1,1,3]]

3. 其他特征选择方法

   1. 神经网络

## 主成分分析

1. sklearn主成分分析API

   1. sklearn.decomposition

   2. PCA是什么

      1. 本质：PCA是一种分析，简化数据集的技术
      2. 目的：是数据维数压缩，尽可能减低原数据的维数（复杂度），**损失少量信息**。
      3. **作用：可以消减回归分析或者聚类分析中特征的数量。**

      - PCA：特征数量达到上百的时候 考虑是否数据简化  数据会改变，特征数量也会减少

      - PCA（主成分分析）

        - 如何最好的对一个立体物体二维表示

      - 通过公式计算（看一下）

        - Y=PX 即为降维到k维后的数据

      - PCA语法

        - PCA(n_components=None)

          - 将数据分解为较低维数空间
          - PCA.fit_transform(X)
            - X：numpy array格式的数据[n_sampels,n_features]
            - 返回值：转换后指定维度的array

        - PCA流程

          1. 初始化PCA，指定减少后的维度

          2. 调用fit_transform

             [[2,8,4,5],

             [6,3,0,8],

             [5,4,9,1]]

## 其他降维方法

- 线性判别分析LDA

  