# 分类模型的评估

- estimator.score()
  - 一般最常见使用的是**准确率**，即预测结果正确的百分比

# 混淆矩阵

- 在分类任务下，预测结果（Predicted Condition）与正确标记（True Condition）之间存在四种不同的组合，构成混淆矩阵（适用于多分类）

  ​											预测结果

  真实结果

  - |      |           正例           |           假例           |
    | :--: | :----------------------: | :----------------------: |
    | 正例 | 真正例 TP true positive  | 伪反例 FN false negative |
    | 假例 | 伪正例 FP false positive | 真反例 TN false positive |

# 精确率(Precision)与召回率(Recall)

- 精确率：**预测结果为正例**样本中真实为正例的比例（查得准）
- 召回率：**真实为正例**的样本中预测结果为正例的比例（查的全，对正样本的区分能力）

- 其他分类标准，F1-score，反映了模型的稳健性
  - F1 = $\frac{2TP}{2TP+FN+FP} = \frac{2·Precision·Recall}{Precision+Recall}$

# 分类模型评估API

- sklearn.metrics.classification_report
  - sklearn.metrics.classification_report(y_true,y_pred,target_names=None)
    - y_true：真实目标值
    - y_pred：估计器预测目标值
    - target_names：目标类别名称
    - return：每个类别精准率与召回率

# 为什么需要指标？

